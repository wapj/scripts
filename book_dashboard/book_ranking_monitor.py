"""
ë„ì„œ ìˆœìœ„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
30ë¶„ë§ˆë‹¤ ë„ì„œ ìˆœìœ„ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
"""

import json
import logging
import sqlite3
import time
from datetime import datetime, timedelta

import schedule

# ë¡œê±° ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)

# í˜„ì¬ ìŠ¤í¬ë˜í¼ ì„í¬íŠ¸
from summary_yozm_ai_agent_info import BookRankingScraper


class BookRankingMonitor:
    def __init__(self, db_path=None):
        """ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        if db_path is None:
            # í™˜ê²½ ë³€ìˆ˜ì—ì„œ DB ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            import os

            self.db_path = os.getenv("DB_PATH", "book_rankings.db")
        else:
            self.db_path = db_path
        self.scraper = BookRankingScraper()
        self.urls = {
            "kyobobook": "https://product.kyobobook.co.kr/detail/S000217241525",
            "yes24": "https://www.yes24.com/product/goods/150701473",
            "aladin": "https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=369431124",
        }
        self.init_database()

    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ë° í…Œì´ë¸” ìƒì„±"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # ë©”ì¸ ìˆœìœ„ ë°ì´í„° í…Œì´ë¸”
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS book_rankings (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp DATETIME NOT NULL,
            scraping_date TEXT NOT NULL,
            
            -- êµë³´ë¬¸ê³  ë°ì´í„°
            kyobo_domestic_rank INTEGER,
            kyobo_it_rank INTEGER,
            kyobo_error TEXT,
            
            -- YES24 ë°ì´í„°
            yes24_sales_index INTEGER,
            yes24_it_mobile_rank INTEGER,
            yes24_error TEXT,
            
            -- ì•Œë¼ë”˜ ë°ì´í„°
            aladin_computer_weekly_rank INTEGER,
            aladin_textbook_rank INTEGER,
            aladin_sales_point INTEGER,
            aladin_rank_period TEXT,
            aladin_error TEXT,
            
            -- ë©”íƒ€ë°ì´í„°
            raw_data TEXT,  -- JSON í˜•íƒœë¡œ ì›ë³¸ ë°ì´í„° ì €ì¥
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
        """)

        # ì¸ë±ìŠ¤ ìƒì„±
        cursor.execute(
            "CREATE INDEX IF NOT EXISTS idx_timestamp ON book_rankings(timestamp)"
        )
        cursor.execute(
            "CREATE INDEX IF NOT EXISTS idx_created_at ON book_rankings(created_at)"
        )

        conn.commit()
        conn.close()
        logging.info(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ: {self.db_path}")

    def save_ranking_data(self, results):
        """ìˆœìœ„ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        try:
            # ë°ì´í„° ì¶”ì¶œ
            timestamp = datetime.now()
            scraping_date = results.get("scraping_date", timestamp.isoformat())

            # êµë³´ë¬¸ê³  ë°ì´í„°
            kyobo = results.get("kyobobook", {})
            kyobo_domestic_rank = kyobo.get("domestic_rank")
            kyobo_it_rank = kyobo.get("it_rank")
            kyobo_error = kyobo.get("error")

            # YES24 ë°ì´í„°
            yes24 = results.get("yes24", {})
            yes24_sales_index = yes24.get("sales_index")
            if yes24_sales_index and isinstance(yes24_sales_index, str):
                try:
                    yes24_sales_index = int(yes24_sales_index.replace(",", ""))
                except:
                    yes24_sales_index = None
            yes24_it_mobile_rank = yes24.get("it_mobile_rank")
            yes24_error = yes24.get("error")

            # ì•Œë¼ë”˜ ë°ì´í„°
            aladin = results.get("aladin", {})
            aladin_computer_weekly_rank = aladin.get("computer_weekly_rank")
            aladin_textbook_rank = aladin.get("textbook_rank")
            aladin_sales_point = aladin.get("sales_point")
            if aladin_sales_point and isinstance(aladin_sales_point, str):
                try:
                    aladin_sales_point = int(aladin_sales_point.replace(",", ""))
                except:
                    aladin_sales_point = None
            aladin_rank_period = aladin.get("rank_period")
            aladin_error = aladin.get("error")

            # ë°ì´í„° ì‚½ì…
            cursor.execute(
                """
            INSERT INTO book_rankings (
                timestamp, scraping_date,
                kyobo_domestic_rank, kyobo_it_rank, kyobo_error,
                yes24_sales_index, yes24_it_mobile_rank, yes24_error,
                aladin_computer_weekly_rank, aladin_textbook_rank, 
                aladin_sales_point, aladin_rank_period, aladin_error,
                raw_data
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    timestamp,
                    scraping_date,
                    kyobo_domestic_rank,
                    kyobo_it_rank,
                    kyobo_error,
                    yes24_sales_index,
                    yes24_it_mobile_rank,
                    yes24_error,
                    aladin_computer_weekly_rank,
                    aladin_textbook_rank,
                    aladin_sales_point,
                    aladin_rank_period,
                    aladin_error,
                    json.dumps(results, ensure_ascii=False),
                ),
            )

            conn.commit()
            logging.info(
                f"âœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ: {timestamp.strftime('%Y-%m-%d %H:%M:%S')}"
            )

        except Exception as e:
            logging.error(f"âŒ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
            conn.rollback()
        finally:
            conn.close()

    def collect_data(self):
        """ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥ ì‹¤í–‰"""
        logging.info(
            f"ğŸ• ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        )

        try:
            # ìŠ¤í¬ë˜í•‘ ì‹¤í–‰
            results = self.scraper.scrape_all(self.urls)

            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            self.save_ranking_data(results)

            # ìš”ì•½ ì¶œë ¥
            self.scraper.print_summary(results)

        except Exception as e:
            logging.error(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}", exc_info=True)

    def get_recent_data(self, hours=24):
        """ìµœê·¼ ë°ì´í„° ì¡°íšŒ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        since = datetime.now() - timedelta(hours=hours)

        cursor.execute(
            """
        SELECT * FROM book_rankings 
        WHERE timestamp >= ? 
        ORDER BY timestamp DESC
        """,
            (since,),
        )

        columns = [description[0] for description in cursor.description]
        results = []
        for row in cursor.fetchall():
            results.append(dict(zip(columns, row)))

        conn.close()
        return results

    def get_stats(self):
        """í†µê³„ ì •ë³´ ì¡°íšŒ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # ì´ ë ˆì½”ë“œ ìˆ˜
        cursor.execute("SELECT COUNT(*) FROM book_rankings")
        total_records = cursor.fetchone()[0]

        # ìµœì‹ /ìµœì˜¤ë˜ëœ ë°ì´í„°
        cursor.execute("SELECT MIN(timestamp), MAX(timestamp) FROM book_rankings")
        oldest, newest = cursor.fetchone()

        # ìµœê·¼ 24ì‹œê°„ ë°ì´í„° ìˆ˜
        since_24h = datetime.now() - timedelta(hours=24)
        cursor.execute(
            "SELECT COUNT(*) FROM book_rankings WHERE timestamp >= ?", (since_24h,)
        )
        recent_24h = cursor.fetchone()[0]

        conn.close()

        return {
            "total_records": total_records,
            "oldest_data": oldest,
            "newest_data": newest,
            "recent_24h": recent_24h,
        }

    def start_scheduler(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ (30ë¶„ë§ˆë‹¤ ì‹¤í–‰)"""
        logging.info("ğŸ“… ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ - 30ë¶„ë§ˆë‹¤ ë°ì´í„° ìˆ˜ì§‘")

        # 30ë¶„ë§ˆë‹¤ ì‹¤í–‰ ìŠ¤ì¼€ì¤„ ë“±ë¡
        schedule.every(1).minutes.do(self.collect_data)

        # ì¦‰ì‹œ í•œ ë²ˆ ì‹¤í–‰
        self.collect_data()

        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰
        while True:
            schedule.run_pending()
            time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬

    def run_once(self):
        """í•œ ë²ˆë§Œ ì‹¤í–‰"""
        self.collect_data()

    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.scraper.close()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description="ë„ì„œ ìˆœìœ„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ")
    parser.add_argument(
        "--once", action="store_true", help="í•œ ë²ˆë§Œ ì‹¤í–‰ (ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘í•˜ì§€ ì•ŠìŒ)"
    )
    parser.add_argument(
        "--db", default="book_rankings.db", help="ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ"
    )
    parser.add_argument("--stats", action="store_true", help="í†µê³„ ì •ë³´ ì¶œë ¥")

    args = parser.parse_args()

    monitor = BookRankingMonitor(db_path=args.db)

    try:
        if args.stats:
            stats = monitor.get_stats()
            logging.info("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ í†µê³„:")
            logging.info(f"  ì´ ë ˆì½”ë“œ ìˆ˜: {stats['total_records']}")
            logging.info(f"  ìµœì˜¤ë˜ëœ ë°ì´í„°: {stats['oldest_data']}")
            logging.info(f"  ìµœì‹  ë°ì´í„°: {stats['newest_data']}")
            logging.info(f"  ìµœê·¼ 24ì‹œê°„ ë ˆì½”ë“œ: {stats['recent_24h']}")

        elif args.once:
            monitor.run_once()
        else:
            monitor.start_scheduler()

    except KeyboardInterrupt:
        logging.info("â¹ï¸  ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨")
    finally:
        monitor.close()


if __name__ == "__main__":
    main()
